{
    "agent_params": {
        "n_actions": 6,
        "gamma": 0.99,
        "entropy_weight": 0.01,
        "clip_grad_norm": 40.0,
        "type": "a2c-lstmk",
        "reward_clip": 1.0,
        "n_channels": 1
    },
    "train_params": {
        "optimizer": "adam",
        "lr": 1e-4
    },
    "env_params": {
        "repeat_action_probability": 0.1,
        "n_recurrent_states": 256,
        "n_stack": 1,
        "n_repeat": 1,
        "env_name": "ALE/Pong-v5"
    },
    "simulation_params": {
        "seed": 88881,
        "n_workers": 6,
        // "n_workers": 1,
        // "serial": true,
        "print_interval": 200,
        "total_step_limit": 200e6,
        "max_steps_per_batch": 20,
        "metric_decay": 0.95,
        "use_mlflow": true,
        "epoch_save_interval": 2,
        "steps_per_epoch": 4e6,
        "use_lock": true,
        "experiment_name": "A3C_Pong",
        "run_name": "lstmk_1frame_jan19"
    }
}