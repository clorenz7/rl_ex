{
    "agent_params": {
        "n_actions": 6,
        "gamma": 0.99,
        "entropy_weight": 0.01,
        "clip_grad_norm": 40.0,
        "type": "a2c-lstm",
        "reward_clip": 1.0
    },
    "train_params": {
        "optimizer": "adam",
        "lr": 1e-4
    },
    "env_params": {
        "env_name": "ALE/Pong-v5",
        "repeat_action_probability": 0.0,
        "n_recurrent_state": 256
    },
    "simulation_params": {
        "seed": 88882,
        "n_workers": 6,
        "print_interval": 200,
        "total_step_limit": 50e6,
        "max_steps_per_batch": 5,
        "metric_decay": 0.95,
        "use_mlflow": true,
        "epoch_save_interval": 2,
        "use_lock": true,
        "experiment_name": "A3C_Pong",
        "run_name": "lstm_jan17"
    }
}