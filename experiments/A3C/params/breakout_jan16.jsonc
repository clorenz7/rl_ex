{
    "agent_params": {
        "n_actions": 4,
        "gamma": 0.99,
        "entropy_weight": 0.01,
        "clip_grad_norm": 100.0,
        "type": "a2c-atari",
        "reward_clip": 1.0,
        "value_loss_factor": 1.0
    },
    "train_params": {
        "optimizer": "rmsprop",
        "lr": 1e-3
    },
    "env_params": {
        "env_name": "ALE/Breakout-v5",
        "repeat_action_probability": 0.0
    },
    "simulation_params": {
        "seed": 8888101,
        "n_workers": 6,
        "print_interval": 200,
        "total_step_limit": 50e6,
        "max_steps_per_batch": 5,
        "metric_decay": 0.95,
        "use_mlflow": true,
        "epoch_save_interval": 2,
        "use_lock": true,
        "experiment_name": "A3C_Breakout",
        "run_name": "jan16"
    }
}